
<하둡 설치하기(Hadoop 2.9.2, JDK8, CentOS 7-64bit)>

1. Centos 7, jdk8 준비
http://mirror.kakao.com/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso
https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 
(jdk-8u221-linux-x64.tar.gz)

2. Vmware workstation Pro 15 준비
VMWare Workstation Pro 15 정품인증 키
xxxxx-xxxxx-xxxxx-xxxxx-xxxxx
(정품인증 키가 없으면 체험형으로 사용해도 무방)

3. Vmware 실행 -> Create a New Virtual Machine -> Typical -> 3번째거 ->
   (Linux, CentOS 7 64-bit) -> Store virtual disk as a single file -> 생성완료 ->
   Edit virtual machine settings -> CD/DVD Detect -> Use ISO image file -> 
   CentOS파일 받은거 선택 -> 완료, 가상머신 실행

4. 설치 환경설정
    언어->한국어
    키보드->한국어 기본적용, 영어(US) 추가, 영어를 위로
    소프트웨어 선택 -> 개발 및 창조를 위한 워크스테이션 -> 완료
    설치대상 -> 기타저장소옵션 -> 파티션을 설정합니다. -> 완료 -> 여기를 클릭하여 자동으로 설정
                -> /, swap 제거 -> 추가버튼 -> swap(용량 5g) -> /(용량기재x, 그냥 추가) -> 완료 -> 변경사항적용
    네트워크 및 호스트명 -> 이더넷 켬 -> 완료 -> 설치시작
    ROOT암호 -> 1234 -> 완료
    사용자생성 -> centos, centos, 1234 -> 완료
    설치완료 후 재부팅

5. 라이센스 동의 -> 설정완료 -> 목록에 없습니까? -> root -> 1234 (root계정 접속)
    -> 다음 -> 다음 -> 다음 -> 건너뛰기
   
    프로그램 -> 시스템도구 -> 설정 -> 개인정보 -> 사생활 -> 자동화면잠금 끔
    프로그램 -> 시스템도구 -> 설정 ->	전원 -> 절전 -> 안함
    Power OFF -> 머신설정 -> 메모리 2GB로

6. 생성한 가상머신에 마우스 오른쪽버튼 -> Manage -> clone -> ... -> Create a full clone
    -> 이름 Master -> 생성완료 -> Master 실행 -> root계정으로 접속

7. open jdk삭제 후 오라클jdk 설치해야함.
rpm -qa | grep jdk (jdk패키지 검색)
yum remove java* (java로 시작하는 모든프로그램 제거)

8. 1번에서 준비한 jdk8 압축풀고 jdk1.8로 폴더명변경후 /usr/local/ 로 폴더복사
   (파일탐색기 - 다른 위치 - 컴퓨터 - usr - local - )

   cd /usr/local/jdk1.8/bin
   ./java  -> 설치확인

9. gedit /etc/profile

맨 아래에 내용추가 후 저장
export JAVA_HOME=/usr/local/jdk1.8
export PATH=$PATH:$JAVA_HOME/bin
export JAVA_OPTS="-Dfile.encoding=UTF-8"
export CLASSPATH="."

10. 변경사항을 시스템에 적용
source /etc/profile
reboot

root계정으로 로그인 -> java -version -> 오라클 jdk 설치확인

11. 하둡 설치 
https://hadoop.apache.org/releases.html -> 2.9.2 binary
압축해제 후 생긴 폴더를 /home/centos/ 로 옮김

12. HADOOP_HOME를 환경변수에 추가해야함
gedit /etc/profile

export JAVA_HOME=/usr/local/jdk1.8
export JAVA_OPTS="-Dfile.encoding=UTF-8"
export CLASSPATH="."
export HADOOP_HOME=/home/centos/hadoop-2.9.2
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"

수정 및 추가작성 완료후 저장

터미널 -> source /etc/profile -> reboot -> 터미널에서 hadoop version -> 설치확인

* 단독모드 완료 

==================================================================================================================

13. ssh설치
yum install openssh*
/user/sbin/sshd (ssh서비스 실행)
ssh-keygen -t rsa -P "" (비밀번호를 생략한 ssh로그인 설정, 공개키와 비밀키 생성)
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys (공개키를 ssh의 인증키로 등록)
chmod 600 ~/.ssh/authorized_keys (인증키의 권한설정)
ssh localhost (ssh 접속 확인)

14. 
@ hadoop-env.sh 수정
gedit $HADOOP_HOME/etc/hadoop/hadoop-env.sh
25번라인 JDK경로수정 (우측하단 몇행 몇열 선택 -> 줄 번호 체크)
export JAVA_HOME=/usr/local/jdk1.8

@ core-site.xml 수정(네임노드 설정파일)
gedit $HADOOP_HOME/etc/hadoop/core-site.xml

<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://localhost:9000</value>
	</property>
</configuration>

@ hdfs-site.xml 수정 (파일복제옵션)
gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml

<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>

15. 
네임노드 포맷
hdfs namenode -format

하둡클러스터 시작
start-dfs.sh

프로세스 확인
jps -> NameNode, DataNode, SecondaryNameNode 시작된것 확인

ResourceManager와 NodeManager 시작
start-yarn.sh

16. 웹브라우저로 확인
http://localhost:50070
http://localhost:8088

17. 동작 테스트 (하둡에서 기본제공되는 WordCount 이용)
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/root
hdfs dfs -mkdir /user/root/conf

hdfs dfs -mkdir /input
hdfs dfs -copyFromLocal /home/centos/hadoop-2.9.2/README.txt /input
hdfs dfs -ls /input

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /input/README.txt ~/wordcount-output
hdfs dfs -ls ~/wordcount-output

hdfs dfs -cat ~/wordcount-output/part-r-00000

* 의사(모조)분산모드 완료

==================================================================================================================

18. 완전분산모드를 위한 가상컴퓨터 생성
Master 가상머신 종료 후
Master에 대해 Manage -> clone -> full clone -> Slave1, Slave2, Slave3 생성

vmware 상단메뉴 -> Edit -> Virtual Networ Editor
-> 오른쪽 하단 Change Settings 선택 -> 권한허용
-> VMnet8의 Subnet IP 세번째 자리를 10으로 변경 
-> OK후 다시 들어가 NAT Settings 선택(VMnet8)
-> Gateway IP를 192.168.10.254로 변경

19. 가상머신 4대를 모두 구동시킨 후 각각 ip를 변경해야함
===============================
ip주소: master-> 192.168.10.1
         slave1 -> 192.168.10.2
         slave2 -> 192.168.10.3
         slave3 -> 192.168.10.4
네트마스크: 255.255.255.0
게이트웨이: 192.168.10.254
네임서버: 192.168.10.254, 168.126.63.1
===============================

머신 실행 후 우측상단 네트워크 아이콘 선택
-> 유선네트워크 설정
-> 유선 - 연결됨 - 오른쪽 톱니바퀴 선택
-> IPv4 -> 수동 체크 -> 위에 작성한대로 ip~네임서버까지 모든 노드에 대해 설정
*네임서버 2개적을때 192.168.10.254, 168.126.63.1 처럼 가운데에 ,로 구분
* ip주소는 각 노드에 맞는 하나만 적을것

적용 후 firefox브라우저에서 구글 열리는지 확인

20. 호스트 설정 (모든 노드에서)
gedit /etc/hosts

원래 내용 지우고 아래 내용 작성
127.0.0.1 localhost
192.168.10.1 master
192.168.10.2 slave1
192.168.10.3 slave2
192.168.10.4 slave3

hosts와 hostname을 일치시켜야함
gedit /etc/hostname

각 노드이름에 맞게 작성
master (master 노드에서)
slave1  (slave1 노드에서)
slave2  (slave2 노드에서)
slave3  (slave3 노드에서)

모든 노드에서 실행
/bin/hostname -F /etc/hostname
-> 터미널 닫았다 다시 열면 hostname이 변경되어있음

모든 노드 재부팅

21. ping 테스트
master -> ping slave1, ping slave2, ping slave3 모두 정상인지 확인
slave들도 자신제외 나머지와 정상적으로 통신하는지 확인할 것

22. SSH 공개키 복사
@ master에서 생성한 공개 키를 모든 datanode로 복사(master에서 실행)
scp -rp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys
scp -rp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys
scp -rp ~/.ssh/authorized_keys root@slave3:~/.ssh/authorized_keys

노드간 ssh접속 되는지 확인
ssh slave1
exit
ssh slave2
exit
ssh slave3
exit

@ 각 Slave1,2,3들에서도 같은 작업 수행 -> !! 공개키 복사할때 자신 제외한 곳에 복사할 것
예) Slave1 에서
scp -rp ~/.ssh/authorized_keys root@master:~/.ssh/authorized_keys
scp -rp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys
scp -rp ~/.ssh/authorized_keys root@slave3:~/.ssh/authorized_keys

23. hadoop-env.sh 수정(master에서 실행)
gedit $HADOOP_HOME/etc/hadoop/hadoop-env.sh
25번라인 JDK경로 수정: export JAVA_HOME=/usr/local/jdk1.8
113번 라인 hadoop daemon의 pid 경로 수정: export HADOOP_PID_DIR=/home/centos/hadoop-2.9.2/pids

24. core-site.xml 수정(모든 노드에서 실행)
gedit $HADOOP_HOME/etc/hadoop/core-site.xml
<value>의 localhost를 master로 수정 (<value>hdfs://master:9000</value>)

25. 
@ HADOOP_HOME 하위에 네임노드와 데이터노드 디렉토리를 만들어야함(master에서 실행)
rm -rf $HADOOP_HOME/namenode
mkdir $HADOOP_HOME/namenode
chown root -R $HADOOP_HOME/namenode
chmod 777 $HADOOP_HOME/namenode

rm -rf $HADOOP_HOME/datanode
mkdir $HADOOP_HOME/datanode
chown root -R $HADOOP_HOME/datanode
chmod 777 $HADOOP_HOME/datanode

@ HADOOP_HOME 하위에 datanode 디렉토리를 만든다(Slave1,2,3에서 실행)
rm -rf $HADOOP_HOME/datanode
mkdir $HADOOP_HOME/datanode
chown root -R $HADOOP_HOME/datanode
chmod 777 $HADOOP_HOME/datanode

26. hdfs-site.xml 수정(모든노드에서 실행)
gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml

@ master에서 작성
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/home/centos/hadoop-2.9.2/namenode</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/home/centos/hadoop-2.9.2/datanode</value>
	</property>
</configuration>

@ 각 Slave에서 작성
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/home/centos/hadoop-2.9.2/datanode</value>
	</property>
</configuration>

27. 잡트래커 설정 (모든노드에서 실행)
@ mapred-site.xml.template 파일을 복사하여 mapred-site.xml 만들기
cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template $HADOOP_HOME/etc/hadoop/mapred-site.xml

@ mapred-site.xml 편집
gedit $HADOOP_HOME/etc/hadoop/mapred-site.xml

<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>

@ yarn-site.xml 편집
gedit $HADOOP_HOME/etc/hadoop/yarn-site.xml

<?xml version="1.0"?>

<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>
</configuration>

28. masters, slaves 파일 편집(master에서만 작업)
gedit $HADOOP_HOME/etc/hadoop/masters

master <- 작성하고 저장

gedit $HADOOP_HOME/etc/hadoop/slaves

master
slave1
slave2
slave3  <- 이렇게 4줄 작성하고 저장

29. 네임노드 포맷(master에서만 실행), 하둡가동, HDFS폴더 생성
$HADOOP_HOME/bin/hdfs namenode -format

30. 방화벽을 내림(모든 노드)
systemctl stop firewalld.service
systemctl disable firewalld.service

31. DFS, YARN 시작(master에서만 실행)
start-dfs.sh
start-yarn.sh

실행 후 프로세스 확인(모든노드 확인)
jps
-> master에서는 Namenode 반드시 떠야함
-> slave에서는 Datanode 반드시 떠야함

32. master에서 웹인터페이스 확인
http://master:50070 (Datanode탭에서 모든 노드가 올라왔는지 확인)
http://master:8088 (작업리스트, 활성노드등 확인가능) 

33. 동작 테스트(wordcount 사용) (master에서 실행)
@ 맵리듀스 job을 실행하기 위해서는 HDFS 디렉토리를 만들어야함
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/root
hdfs dfs -mkdir /user/root/conf

@ 테스트 파일을 HDFS에 업로드
hdfs dfs -mkdir /input
hdfs dfs -copyFromLocal /home/centos/hadoop-2.9.2/README.txt /input
hdfs dfs -ls /input

@ wordcount 프로그램 실행 (hadoop jar jar파일경로 클래스 입력파일 출력폴더)
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /input/README.txt ~/wordcount-output

@ 작업결과 확인
hdfs dfs -ls ~/wordcount-output
hdfs dfs -cat ~/wordcount-output/part-r-00000

* 완전분산모드 완료

==================================================================================================================