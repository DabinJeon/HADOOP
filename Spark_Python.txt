
< python 코드로 Spark 사용 >

$ hdfs dfs -mkdir /sample
$ hdfs dfs -copyFromLocal /home/centos/spark-2.3.3-bin-hadoop2.7/README.md /sample

$ vim test.py => python code 작성

----------------------------------------------------------------
from pyspark import SparkContext

logFile = "/sample/README.md" 
//hdfs에 올려둔 파일사용 ( hdfs://master:9000/sample/README.md )

sc = SparkContext("local","Simple App")
logData = sc.textFile(logFile).cache()

numA = logData.filter(lambda s: 'a' in s).count()
numB = logData.filter(lambda s: 'b; in s).count()

print("lines with a: %i, lines with b:%i" %(numA,numB))
-----------------------------------------------------------------

$ bin/spark-submit --master local[4] test.py

